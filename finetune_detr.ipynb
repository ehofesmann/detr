{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep\n",
    "\n",
    "Setting up some prior functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/thepycoder/detr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferably run this in a terminal if you can, but if in a (colab) notebook, the input is not recognised properly. Press enter once, to give clearml-init an empty input and then fill in the fields one at a time.\n",
    "!clearml-init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data from the clearML server (I just had to run `clearml-data get` to get a local copy of my data)\n",
    "!wget https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
    "!unzip dataset.731383ca315447a8bbaf91c4a8bdecf2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the clearml-specific code is added in the `main.py` file and will keep track of every time it is ran from here. Keeping track of all the variables, arguments, metrics, model files and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a model\n",
    "\n",
    "First we have to decide if our model should be pretrained. \n",
    "\n",
    "This greatly depends on the size of a dataset. Smaller datasets rely more on finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained weights\n",
    "checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url='https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth',\n",
    "            map_location='cpu',\n",
    "            check_hash=True)\n",
    "\n",
    "# Remove class weights\n",
    "del checkpoint[\"model\"][\"class_embed.weight\"]\n",
    "del checkpoint[\"model\"][\"class_embed.bias\"]\n",
    "\n",
    "# SaveOGH\n",
    "torch.save(checkpoint, 'detr-r50_no-class-head.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Our dataset should be loadable as a COCO format\n",
    "\n",
    "This allows us to use the pycocotools to load the data dict for the main python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = \"dragons\" # alternatively, implement your own coco-type dataset loader in datasets and add this \"key\" to datasets/__init__.py\n",
    "\n",
    "dataDir='/project/data/coco_format' # should lead to a directory with a train and val folder as well as an annotations folder\n",
    "num_classes = 1 # this int should be the highest ID in your annotations + 1 (for no class) (so here: dragon is class ID 0 and the only one so: 0+1 = 1)\n",
    "\n",
    "outDir = 'outputs'\n",
    "resume = \"detr-r50_no-class-head.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "We use the main.py script to run our training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py \\\n",
    "  --dataset_file $dataset_file \\\n",
    "  --coco_path $dataDir \\\n",
    "  --output_dir $outDir \\\n",
    "  --resume $resume \\\n",
    "  --num_classes $num_classes \\\n",
    "  --lr 1e-5 \\\n",
    "  --lr_backbone 1e-6 \\\n",
    "  --epochs 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Quick and easy overview of the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.plot_utils import plot_logs\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "log_directory = [Path(outDir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = (\n",
    "    'loss',\n",
    "    'mAP',\n",
    "    )\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = (\n",
    "    'loss_ce',\n",
    "    'loss_bbox',\n",
    "    'loss_giou',\n",
    "    )\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = (\n",
    "    'class_error',\n",
    "    'cardinality_error_unscaled',\n",
    "    )\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('immo': venv)",
   "language": "python",
   "name": "python361064bitimmovenv72400f0fe6484ab0a0a8757524f2ee9f"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}