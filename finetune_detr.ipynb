{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep\n",
    "\n",
    "Setting up some prior functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/thepycoder/detr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0 True\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clearml in /opt/conda/lib/python3.7/site-packages (1.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from clearml) (2.8.2)\n",
      "Requirement already satisfied: future>=0.16.0 in /opt/conda/lib/python3.7/site-packages (from clearml) (0.18.2)\n",
      "Requirement already satisfied: pathlib2>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from clearml) (2.3.6)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from clearml) (2.25.1)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from clearml) (1.26.6)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /opt/conda/lib/python3.7/site-packages (from clearml) (5.3.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from clearml) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from clearml) (3.0.4)\n",
      "Requirement already satisfied: Pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from clearml) (7.2.0)\n",
      "Requirement already satisfied: pyjwt<=2.1.0,>=1.6.4 in /opt/conda/lib/python3.7/site-packages (from clearml) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.10 in /opt/conda/lib/python3.7/site-packages (from clearml) (1.21.2)\n",
      "Requirement already satisfied: furl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from clearml) (2.1.3)\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from clearml) (3.2.0)\n",
      "Requirement already satisfied: attrs>=18.0 in /opt/conda/lib/python3.7/site-packages (from clearml) (21.2.0)\n",
      "Requirement already satisfied: psutil>=3.4.2 in /opt/conda/lib/python3.7/site-packages (from clearml) (5.8.0)\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from furl>=2.0.0->clearml) (1.0.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6.0->clearml) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6.0->clearml) (58.0.4)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6.0->clearml) (4.8.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->clearml) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->clearml) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->clearml) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema>=2.6.0->clearml) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema>=2.6.0->clearml) (3.10.0.2)\n",
      "ClearML SDK setup process\n",
      "Configuration file already exists: /root/clearml.conf\n",
      "Leaving setup, feel free to edit the configuration file.\n"
     ]
    }
   ],
   "source": [
    "# Preferably run this in a terminal if you can, but if in a (colab) notebook, the input is not recognised properly. Press enter once, to give clearml-init an empty input and then fill in the fields one at a time.\n",
    "!pip install clearml\n",
    "!clearml-init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data from the clearML server (I just had to run `clearml-data get` to get a local copy of my data)\n",
    "!wget https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
    "!unzip dataset.731383ca315447a8bbaf91c4a8bdecf2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clearml-data - Dataset Management & Versioning CLI\n",
      "Download dataset id 731383ca315447a8bbaf91c4a8bdecf2\n",
      "2021-11-14 19:26:19,226 - clearml.storage - INFO - Downloading: 5.00MB / 57.74MB @ 2.91MBs from https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
      "2021-11-14 19:26:20,812 - clearml.storage - INFO - Downloading: 10.00MB / 57.74MB @ 3.15MBs from https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
      "2021-11-14 19:26:22,515 - clearml.storage - INFO - Downloading: 15.00MB / 57.74MB @ 2.94MBs from https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
      "2021-11-14 19:26:24,222 - clearml.storage - INFO - Downloading: 20.00MB / 57.74MB @ 2.93MBs from https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
      "2021-11-14 19:26:26,045 - clearml.storage - INFO - Downloading: 25.00MB / 57.74MB @ 2.74MBs from https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
      "2021-11-14 19:26:27,924 - clearml.storage - INFO - Downloading: 30.00MB / 57.74MB @ 2.66MBs from https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
      "2021-11-14 19:26:29,746 - clearml.storage - INFO - Downloading: 35.00MB / 57.74MB @ 2.74MBs from https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
      "2021-11-14 19:26:32,304 - clearml.storage - INFO - Downloading: 40.00MB / 57.74MB @ 1.95MBs from https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
      "2021-11-14 19:26:34,825 - clearml.storage - INFO - Downloading: 45.00MB / 57.74MB @ 1.98MBs from https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
      "2021-11-14 19:26:37,241 - clearml.storage - INFO - Downloading: 50.00MB / 57.74MB @ 2.07MBs from https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
      "2021-11-14 19:26:39,420 - clearml.storage - INFO - Downloading: 55.00MB / 57.74MB @ 2.29MBs from https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
      "2021-11-14 19:26:40,969 - clearml.storage - INFO - Downloaded 57.74 MB successfully from https://files.community.clear.ml/dragon_detector/dragon_coco.731383ca315447a8bbaf91c4a8bdecf2/artifacts/data/dataset.731383ca315447a8bbaf91c4a8bdecf2.zip , saved to /root/.clearml/cache/storage_manager/datasets/d505ac4893e0c873b7e4b1514f565f6a.dataset.731383ca315447a8bbaf91c4a8bdecf2.zip\n",
      "Dataset local copy available: dragon_data\n"
     ]
    }
   ],
   "source": [
    "# This is for myself\n",
    "!clearml-data get --id 731383ca315447a8bbaf91c4a8bdecf2 --copy dragon_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the clearml-specific code is added in the `main.py` file and will keep track of every time it is ran from here. Keeping track of all the variables, arguments, metrics, model files and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a model\n",
    "\n",
    "Since the data in our dragon dataset is limited, our model should be pretrained. \n",
    "\n",
    "This means getting a pretrained model and chopping off the class head, so we can retrain that part only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd detr\n",
    "# Get pretrained weights\n",
    "checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url='https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth',\n",
    "            map_location='cpu',\n",
    "            check_hash=True)\n",
    "\n",
    "# Remove class weights\n",
    "del checkpoint[\"model\"][\"class_embed.weight\"]\n",
    "del checkpoint[\"model\"][\"class_embed.bias\"]\n",
    "\n",
    "# SaveOGH\n",
    "torch.save(checkpoint, 'detr-r50_no-class-head.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Our dataset should be loadable as a COCO format\n",
    "\n",
    "This allows us to use the pycocotools to load the data dict for the main python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = \"dragons\" # alternatively, implement your own coco-type dataset loader in datasets and add this \"key\" to datasets/__init__.py\n",
    "\n",
    "dataDir='/content/dragon_data' # should lead to a directory with a train and val folder as well as an annotations folder\n",
    "num_classes = 1 # this int should be the highest ID in your annotations + 1 (for no class) (so here: dragon is class ID 0 and the only one so: 0+1 = 1)\n",
    "\n",
    "outDir = 'outputs'\n",
    "resume = \"detr-r50_no-class-head.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "We use the main.py script to run our training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py \\\n",
    "  --dataset_file $dataset_file \\\n",
    "  --coco_path $dataDir \\\n",
    "  --output_dir $outDir \\\n",
    "  --resume $resume \\\n",
    "  --num_classes $num_classes \\\n",
    "  --lr 1e-5 \\\n",
    "  --lr_backbone 1e-6 \\\n",
    "  --epochs 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Quick and easy overview of the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.plot_utils import plot_logs\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "log_directory = [Path(outDir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = (\n",
    "    'loss',\n",
    "    'mAP',\n",
    "    )\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = (\n",
    "    'loss_ce',\n",
    "    'loss_bbox',\n",
    "    'loss_giou',\n",
    "    )\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = (\n",
    "    'class_error',\n",
    "    'cardinality_error_unscaled',\n",
    "    )\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('facebookresearch/detr',\n",
    "                       'detr_resnet50',\n",
    "                       pretrained=False,\n",
    "                       num_classes=num_classes)\n",
    "\n",
    "checkpoint = torch.load('outputs/checkpoint.pth',\n",
    "                        map_location='cpu')\n",
    "\n",
    "model.load_state_dict(checkpoint['model'],\n",
    "                      strict=False)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# colors for visualization\n",
    "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]\n",
    "\n",
    "finetuned_classes = ['dragon']\n",
    "\n",
    "def plot_finetuned_results(pil_img, prob=None, boxes=None):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    if prob is not None and boxes is not None:\n",
    "      for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n",
    "          ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                    fill=False, color=c, linewidth=3))\n",
    "          cl = p.argmax()\n",
    "          text = f'{finetuned_classes[cl]}: {p[cl]:0.2f}'\n",
    "          ax.text(xmin, ymin, text, fontsize=15,\n",
    "                  bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "# standard PyTorch mean-std input image normalization\n",
    "transform = T.Compose([\n",
    "    T.Resize(800),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b\n",
    "\n",
    "\n",
    "def filter_bboxes_from_outputs(outputs,\n",
    "                               threshold=0.1):\n",
    "  \n",
    "  # keep only predictions with confidence above threshold\n",
    "  probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
    "  keep = probas.max(-1).values > threshold\n",
    "\n",
    "  probas_to_keep = probas[keep]\n",
    "\n",
    "  # convert boxes from [0; 1] to image scales\n",
    "  bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)\n",
    "  \n",
    "  return probas_to_keep, bboxes_scaled\n",
    "\n",
    "def run_worflow(my_image, my_model):\n",
    "  # mean-std normalize the input image (batch-size: 1)\n",
    "  img = transform(my_image).unsqueeze(0)\n",
    "\n",
    "  # propagate through the model\n",
    "  outputs = my_model(img)\n",
    "\n",
    "  for threshold in [0.7, 0.2]:\n",
    "    \n",
    "    probas_to_keep, bboxes_scaled = filter_bboxes_from_outputs(outputs,\n",
    "                                                              threshold=threshold)\n",
    "\n",
    "    plot_finetuned_results(my_image,\n",
    "                           probas_to_keep, \n",
    "                           bboxes_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_name = '/content/dragon_data/val/dsfgfdsfgdsfg.jpg'\n",
    "im = Image.open(img_name)\n",
    "\n",
    "run_worflow(im,\n",
    "            model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}